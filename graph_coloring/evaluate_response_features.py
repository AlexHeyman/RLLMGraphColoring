'''
When run, this file reads through the responses in the response directory,
parses them for non-answer features like length and edge hallucinations, and
records the results in the 'response_features' subdirectory of the evaluation
directory. If any model/problem set/frame combination already has a
corresponding file in the response features directory, it will not be
re-evaluated unless the file is deleted. Any model/problem set/frame
combination evaluated by this file is expected to already have a corresponding
file generated by evaluate.py in the base evaluation directory. As this file
executes, it will generate text files in two subdirectories of the response
features directory: 'false_edge_statements' (for apparent edge hallucinations
found by an automatic parser) and 'manual_fes_searches' (for responses that
should be manually reviewed for edge hallucinations). These text files have
labeled places where manual assessments can be written in, and these will be
incorporated into this file's output if the relevant model/problem set/frame
combinations are re-evaluated. For 'false_edge_statements' files, write "false
positive" for erroneously detected edge hallucinations; for
'manual_fes_searches' files, write hallucinated edges in a format like 3,5|6,7
to represent the hallucination of edges (3, 5) and (6, 7).

This file does not run with any arguments.
'''

from os import path, listdir, makedirs, remove
import re
import itertools

from metadata import *
from utils import get_clean_tokens, compute_vertex_conns, edges_to_string,\
     string_to_coloring, coloring_is_valid, color_greedy

clause_sep_re = re.compile(r"((\.\D)|(,\D)|:|;|\?|!)")
no_re = re.compile(r"\bno\b|\bnot\b|\bnor\b|n't\b|\bnon|\bnowhere\b")
digits_re = re.compile(r"\d+")
paren_re = re.compile(r"\((\w| |')+\)")

friends_replace = {}
friends_replace_wi = {}

for i, name in enumerate(friends_names):
  i_str = '#' + str(i)
  friends_replace[name] = i_str
  friends_replace_wi[name] = i_str
  friends_replace_wi[name[0]] = i_str

def starts_with_any(string, prefixes):
  for prefix in prefixes:
    if string.startswith(prefix):
      return True
  return False

def ends_with_any(string, suffixes):
  for suffix in suffixes:
    if string.endswith(suffix):
      return True
  return False

def contains_any_whole_word(string, words):
  escaped_words = [re.escape(w) for w in words]
  pattern = re.compile(r'\b(' + '|'.join(escaped_words) + r')\b')
  return pattern.search(string) is not None

def replace_each_whole_word(string, replace_dict):
  escaped_keys = [re.escape(k) for k in replace_dict.keys()]
  pattern = re.compile(r'\b(' + '|'.join(escaped_keys) + r')\b')
  return pattern.sub(lambda match: replace_dict[match.group()], string)

def es_preamble_search(string, index, boundary, clause_seps):
  paren_depth = 0
  preamble_chars = []
  index -= 1
  
  while index >= boundary:
    if paren_depth == 0 and index in clause_seps:
      break
    
    if string[index] == ')':
      paren_depth += 1
    
    if paren_depth == 0:
      preamble_chars.append(string[index])
    else:
      preamble_chars.append(' ')
    
    if string[index] == '(':
      paren_depth -= 1
      if paren_depth < 0:
        preamble_chars.pop()
        break
    
    index -= 1
  
  return index + 1, ''.join(reversed(preamble_chars))

def es_postscript_search(string, index, boundary, clause_seps):
  paren_depth = 0
  postscript_chars = []
  
  while index < boundary:
    if paren_depth == 0 and index in clause_seps:
      postscript_chars.append(string[index])
      break
    
    if string[index] == '(':
      paren_depth += 1
    
    if paren_depth == 0:
      postscript_chars.append(string[index])
    else:
      postscript_chars.append(' ')
    
    if string[index] == ')':
      paren_depth -= 1
      if paren_depth < 0:
        postscript_chars.pop()
        break
    
    index += 1
  
  return index, ''.join(postscript_chars)

def es_preamble_invalidity_heuristic(string):
  if string == 'is':
    return True
  
  if no_re.search(string) is not None:
    return True
  
  if contains_any_whole_word(string, ['if', 'whether', 'or', 'possible',
    'missing', 'minus', 'no mention', 'complement', 'complementary']):
    return True
  
  return False

def find_edge_statements(model, problem_set, frame, filename, lines):
  ps_short_name = problem_set['short_name']
  
  if model == 'deepseek-r1' or model == 'claude3.7s-think'\
  or model == 'grok3mb-low' or model == 'grok3mb-high':
    if frame == 'math':
      return fes_math(lines)
    elif frame == 'friends':
      return fes_friends(lines)
  
  if model == 'gemini2.5pp'\
  and (ps_short_name == '8v4c_hec_col' or ps_short_name == '8v4c_adv'):
    return fes_gemini2point5pp_8v4c_extra(lines, frame)
  
  return None

def do_manual_fes_search(model, problem_set, frame, filename, coloring,
                         evaluation):
  if not (coloring == 'impossible' and evaluation == 'incorrect'):
    return False
  return (model == 'o1-mini' or model == 'o3-mini-low'\
          or model == 'o3-mini-medium' or model == 'o3-mini-high'\
          or model == 'gemini2.5pp')

math_re1 = re.compile(r"\b\d+(:| is|. It's)? (only )?(connect(s|ed)|adjacent) to( |: ?)")
math_re2 = re.compile(r"\b\d+('s|. Its) neighbors(: ?|( are(:| )))")
math_re3 = re.compile(r"\b((vertex )?\d+ ?(\((\w| |')+\))?,? ?){2,}(and (vertex )?\d+ ?(\((\w| |')+\))?)?")
math_re4 = re.compile(r"\b((vertex )?\d+ ?(\((\w| |')+\))? ?)(and (vertex )?\d+ ?(\((\w| |')+\))?)?")
math_re5 = re.compile(r"\b(edges:|are:?)")
math_re6 = re.compile(r"\((?P<v1>\d+), ?(?P<v2>\d+)\),?")
math_re7 = re.compile(r"\b(?P<v1>\d+) ?-{1,3} ?(?P<v2>\d+),?")
math_re8 = re.compile(r"\b(?P<v1>\d+) connect(s|ed) to (?P<v2>\d+),?")

def fes_math(lines):
  statements = {}
  
  current_list = None
  
  for i in range(len(lines)):
    line = lines[i].strip()
    
    if len(line) == 0:
      continue
    
    line = line.lower()
    
    if contains_any_whole_word(line, ['in complement']):
      continue
    
    v1_locs = [m.span() for m in math_re1.finditer(line)]
    v1_locs.extend(m.span() for m in math_re2.finditer(line))
    v1_locs.sort(key=lambda span: span[0])
    
    clause_seps = set(m.start() for m in clause_sep_re.finditer(line))
    preamble_boundary = 0
    
    for j in range(len(v1_locs)):
      start, end = v1_locs[j]
      if j == len(v1_locs) - 1:
        v2_area_end = len(line)
      else:
        v2_area_end = v1_locs[j + 1][0]
      
      _, preamble = es_preamble_search(
        line, start, preamble_boundary, clause_seps)
      preamble = preamble.strip()
      
      if ends_with_any(preamble, ['degree'])\
      or es_preamble_invalidity_heuristic(preamble):
        continue
      
      v2m = math_re3.match(line, end, v2_area_end)
      if v2m is None:
        v2m = math_re4.match(line, end, v2_area_end)
      
      if v2m is None:
        continue
      
      v2m_start, v2m_end = v2m.span()
      preamble_boundary = v2m_end
      _, postscript = es_postscript_search(
        line, v2m_end, v2_area_end, clause_seps)
      postscript = postscript.strip()
      
      if starts_with_any(postscript, ['if', 'only if', 'via', 'through'])\
      or postscript.endswith('?')\
      or line[v2m_end:].startswith(': no')\
      or (preamble.endswith('"') and postscript.startswith('"'))\
      or (preamble.endswith('“') and postscript.startswith('”')):
        continue
      
      v1 = int(digits_re.match(line, start, end).group())
      v2m_no_paren = paren_re.sub(' ', line[v2m_start:v2m_end])
      v2_list = [int(m.group()) for m in digits_re.finditer(v2m_no_paren)]
      
      if starts_with_any(postscript, ["'s", 'to', 'is', 'has', 'can', 'must',
          'connect', 'vert', 'node', 'edge', 'other']):
        v2_list = v2_list[:-1]
      
      for v2 in v2_list:
        if v1 != v2:
          statement = tuple(sorted((v1, v2)))
          if i not in statements:
            statements[i] = set()
          statements[i].add(statement)
    
    while len(line) > 0:
      if current_list is None:
        start_match = math_re5.search(line)
        
        if start_match is None:
          break
        
        start, end = start_match.span()
        p_clause_seps = set(m.start()\
                            for m in clause_sep_re.finditer(line[:start]))
        _, preamble = es_preamble_search(line, start, 0, p_clause_seps)
        preamble = preamble.strip()
        
        if ends_with_any(preamble, ['vertices', 'vertex numbers'])\
        or es_preamble_invalidity_heuristic(preamble):
          line = line[end:].lstrip()
          continue
        
        line = line[end:].lstrip()
        current_list = []
      else:
        edge_match = math_re6.match(line)
        if edge_match is None:
          edge_match = math_re7.match(line)
        if edge_match is None:
          edge_match = math_re8.match(line)
        
        if edge_match is None:
          if not starts_with_any(line, ['?', 'are not'])\
          and not (len(current_list) == 1\
                   and starts_with_any(line, ['=', 'is not'])):
            for line_index, statement in current_list:
              if line_index not in statements:
                statements[line_index] = set()
              statements[line_index].add(statement)
          
          current_list = None
          continue
        
        edge_match_groupdict = edge_match.groupdict()
        v1 = int(edge_match_groupdict['v1'])
        v2 = int(edge_match_groupdict['v2'])
        
        if v1 != v2:
          statement = tuple(sorted((v1, v2)))
          current_list.append((i, statement))
        
        line = line[edge_match.end():].lstrip()
  
  return statements

friends_re1 = re.compile(r"#\d+(:| is|. He's|. She's)? (only )?(connect(s|ed) to|adjacent to|friends( with)?|with)( |: ?)")
friends_re2 = re.compile(r"#\d+('s|. His|. Her) (neighbors|friends)(: ?|( are(:| )))")
friends_re3 = re.compile(r"(#\d+ ?(\((\w| |')+\))?,? ?){2,}(and #\d+ ?(\((\w| |')+\))?)?")
friends_re4 = re.compile(r"(#\d+ ?(\((\w| |')+\))? ?)(and #\d+ ?(\((\w| |')+\))?)?")
friends_re5 = re.compile(r"(edges:|friendships:|are:?)")
friends_re6 = re.compile(r"\(#(?P<v1>\d+), ?#(?P<v2>\d+)\),?")
friends_re7 = re.compile(r"#(?P<v1>\d+) ?-{1,3} ?#(?P<v2>\d+),?")
friends_re8 = re.compile(r"#(?P<v1>\d+) (connect(s|ed) to|friends with) #(?P<v2>\d+),?")
friends_re9 = re.compile(r"#\d+ ?(\((\w| |')+\))? and #\d+ ?(\((\w| |')+\))? are friends")

def fes_friends(lines):
  statements = {}
  
  current_list = None
  
  for i in range(len(lines)):
    line = lines[i].strip()
    
    if len(line) == 0:
      continue
    
    line = replace_each_whole_word(line, friends_replace).lower()
    
    if contains_any_whole_word(line, ['in complement']):
      continue
    
    v1_locs = [(m.span(), 0) for m in friends_re1.finditer(line)]
    v1_locs.extend(
      (m.span(), 0) for m in friends_re2.finditer(line))
    v1_locs.extend(
      (m.span(), 1) for m in friends_re9.finditer(line))
    v1_locs.sort(key=lambda entry: entry[0][0])
    
    clause_seps = set(m.start() for m in clause_sep_re.finditer(line))
    preamble_boundary = 0
    
    for j in range(len(v1_locs)):
      start, end = v1_locs[j][0]
      if j == len(v1_locs) - 1:
        v2_area_end = len(line)
      else:
        v2_area_end = v1_locs[j + 1][0][0]
      
      _, preamble = es_preamble_search(
        line, start, preamble_boundary, clause_seps)
      preamble = preamble.strip()
      
      if ends_with_any(preamble, ['degree'])\
      or es_preamble_invalidity_heuristic(preamble):
        continue
      
      match_type = v1_locs[j][1]
      
      if match_type == 0:
        v2m = friends_re3.match(line, end, v2_area_end)
        if v2m is None:
          v2m = friends_re4.match(line, end, v2_area_end)
        
        if v2m is None:
          continue
        
        v2m_start, v2m_end = v2m.span()
        preamble_boundary = v2m_end
        _, postscript = es_postscript_search(
          line, v2m_end, v2_area_end, clause_seps)
        postscript = postscript.strip()
        
        if starts_with_any(postscript, ['if', 'only if', 'via', 'through'])\
        or postscript.endswith('?')\
        or line[v2m_end:].startswith(': no')\
        or (preamble.endswith('"') and postscript.startswith('"'))\
        or (preamble.endswith('“') and postscript.startswith('”')):
          continue
        
        v1 = int(digits_re.match(line, start + 1, end).group())
        v2m_no_paren = paren_re.sub(' ', line[v2m_start:v2m_end])
        v2_list = [int(m.group()) for m in digits_re.finditer(v2m_no_paren)]
        
        if starts_with_any(postscript, ["'s", 'to', 'is', 'has', 'can', 'must',
            'connect', 'vert', 'node', 'edge', 'person', 'people', 'other']):
          v2_list = v2_list[:-1]
      else: # match_type == 1
        preamble_boundary = end
        _, postscript = es_postscript_search(
          line, end, v2_area_end, clause_seps)
        postscript = postscript.strip()
        
        if starts_with_any(postscript, ['if', 'only if', 'via', 'through',
                                        'with', 'only with', 'of'])\
        or postscript.endswith('?')\
        or line[end:].startswith(': no')\
        or (preamble.endswith('"') and postscript.startswith('"'))\
        or (preamble.endswith('“') and postscript.startswith('”')):
          continue
        
        match_no_paren = paren_re.sub(' ', line[start:end])
        v_list = [int(m.group()) for m in digits_re.finditer(match_no_paren)]
        v1 = v_list[0]
        v2_list = [v_list[1]]
      
      for v2 in v2_list:
        if v1 != v2:
          statement = tuple(sorted((v1, v2)))
          if i not in statements:
            statements[i] = set()
          statements[i].add(statement)
    
    while len(line) > 0:
      if current_list is None:
        start_match = friends_re5.search(line)
        
        if start_match is None:
          break
        
        start, end = start_match.span()
        p_clause_seps = set(m.start()\
                            for m in clause_sep_re.finditer(line[:start]))
        _, preamble = es_preamble_search(line, start, 0, p_clause_seps)
        preamble = preamble.strip()
        
        if ends_with_any(preamble, ['vertices', 'vertex numbers'])\
        or es_preamble_invalidity_heuristic(preamble):
          line = line[end:].lstrip()
          continue
        
        line = line[end:].lstrip()
        current_list = []
      else:
        edge_match = friends_re6.match(line)
        if edge_match is None:
          edge_match = friends_re7.match(line)
        if edge_match is None:
          edge_match = friends_re8.match(line)
        
        if edge_match is None:
          if not starts_with_any(line, ['?', 'are not'])\
          and not (len(current_list) == 1\
                   and starts_with_any(line, ['=', 'is not'])):
            for line_index, statement in current_list:
              if line_index not in statements:
                statements[line_index] = set()
              statements[line_index].add(statement)
          
          current_list = None
          continue
        
        edge_match_groupdict = edge_match.groupdict()
        v1 = int(edge_match_groupdict['v1'])
        v2 = int(edge_match_groupdict['v2'])
        
        if v1 != v2:
          statement = tuple(sorted((v1, v2)))
          current_list.append((i, statement))
        
        line = line[edge_match.end():].lstrip()
  
  return statements

gemini_math_clique_re = re.compile(r"\\?{\s*(\d+,\s*)+\d+\s*\\?}")
gemini_friends_clique_re = re.compile(r"\\?{\s*(#\d+,\s*)+#\d+\s*\\?}")

def fes_gemini2point5pp_8v4c_extra(lines, frame):
  statements = {}
  stated_edges = set()
  
  clique_re = gemini_math_clique_re
  if frame == 'friends':
    clique_re = gemini_friends_clique_re
  
  for i in reversed(range(len(lines))):
    line = lines[i].strip()
    
    if len(line) == 0:
      continue
    
    if frame == 'friends':
      line = replace_each_whole_word(line, friends_replace_wi)
    
    line = line.lower()
    
    if not contains_any_whole_word(line, ['clique', 'cliques'])\
    or contains_any_whole_word(line, ['check'])\
    or no_re.search(line) is not None:
      continue
    
    clique_locs = [m.span() for m in clique_re.finditer(line)]
    
    for start, end in clique_locs:
      vertices = [int(m.group()) for m in digits_re.finditer(line, start, end)]
      for v1, v2 in itertools.combinations(vertices, 2):
        statement = tuple(sorted((v1, v2)))
        if statement not in stated_edges:
          stated_edges.add(statement)
          if i not in statements:
            statements[i] = set()
          statements[i].add(statement)
  
  if len(statements) == 0:
    return None
  
  return statements

for model in models:
  for problem_set in problem_sets:
    ps_short_name = problem_set['short_name']
    num_vertices = problem_set['num_vertices']
    num_colors = problem_set['num_colors']
    
    if 'search_for_fes' in problem_set:
      search_for_fes = problem_set['search_for_fes']
    else:
      search_for_fes = 'all'
    
    possible_edges = list(itertools.combinations(range(num_vertices), 2))
    
    ps_data_dir = path.join(data_dir, ps_short_name)
    mps_response_dir = path.join(response_dir, model, ps_short_name)
    
    if not path.exists(ps_data_dir) or not path.exists(mps_response_dir):
      continue
    
    features_file_paths = []
    false_es_file_paths = []
    manual_fes_paths = []
    mps_frame_indices = []
    repeat_dirs = []
    
    for i in range(len(frames)):
      f_response_dir = path.join(mps_response_dir, frames[i])
      f_filename = '%s_%s_%s.txt' % (model, ps_short_name, frames[i])
      features_file_paths.append(path.join(evaluation_dir, 'response_features',
                                           f_filename))
      false_es_file_paths.append(path.join(evaluation_dir, 'response_features',
                                           'false_edge_statements', f_filename))
      manual_fes_paths.append(path.join(evaluation_dir, 'response_features',
        'manual_fes_searches', model, ps_short_name, frames[i]))
      
      if not path.exists(f_response_dir)\
      or path.exists(features_file_paths[-1]):
        continue
      
      mps_frame_indices.append(i)
      f_repeat_dirs = []
      
      for filename in listdir(f_response_dir):
        file_path = path.join(f_response_dir, filename)
        if path.isdir(file_path):
          f_repeat_dirs.append(file_path)
      
      if len(f_repeat_dirs) == 0:
        f_repeat_dirs.append(f_response_dir)
      
      repeat_dirs.append(f_repeat_dirs)
    
    if len(mps_frame_indices) == 0:
      continue
    
    print('Evaluating response features for %s %s' % (model, ps_short_name))
    
    filenames = list(listdir(ps_data_dir))
    filename_indices = {filenames[k]: k for k in range(len(filenames))}
    repeat_indices = [{path.basename(repeat_dirs[m][j]): j
                       for j in range(len(repeat_dirs[m]))}
                      for m in range(len(mps_frame_indices))]
    problem_edges = [None for k in range(len(filenames))]
    features = [[[] for j in range(len(repeat_dirs[m]))]
                for m in range(len(mps_frame_indices))]
    evals = [[[None for f in filenames] for j in range(len(repeat_dirs[m]))]
             for m in range(len(mps_frame_indices))]
    overrides = [{} for m in range(len(mps_frame_indices))]
    manual_fes = [{} for m in range(len(mps_frame_indices))]
    
    for m in range(len(mps_frame_indices)):
      i = mps_frame_indices[m]
      
      eval_file_path = path.join(evaluation_dir,
        '%s_%s_%s.txt' % (model, ps_short_name, frames[i]))
      eval_file = open(eval_file_path, 'r')
      
      for line in eval_file:
        line = line.strip()
        
        if len(line) == 0:
          continue
        
        filename, repeat, is_possible, coloring, evaluation = line.split()
        
        problem_index = filename_indices[filename]
        repeat_index = repeat_indices[m][repeat]
        
        evals[m][repeat_index][problem_index] = (coloring, evaluation)
      
      eval_file.close()
      
      if path.exists(false_es_file_paths[i]):
        false_es_file = open(false_es_file_paths[i], 'r', encoding='utf-8')
        lines = false_es_file.read().splitlines()
        false_es_file.close()
        
        li = -1
        current_line = None
        
        def advance():
          global li, current_line
          while True:
            li += 1
            
            if li >= len(lines):
              return True
            
            current_line = lines[li].strip()
            
            if len(current_line) != 0:
              return False
        
        def parse():
          global li, current_line
          if advance(): return
          while True:
            filename, repeat = current_line.split()
            overrides_key = (filename, repeat)
            if advance(): return
            while current_line != '---':
              line_index = int(current_line.split()[1]) - 1
              if advance(): return
              if advance(): return
              if advance(): return
              while current_line[-1] == ']':
                edge, current_line = current_line.split('[')
                assessment = current_line.split(':')[1]
                
                edge = edge.rstrip()[1:-1].split(',')
                edge = tuple(int(v.strip()) for v in edge)
                
                assessment = assessment[:-1].strip()
                
                if assessment != 'N/A':
                  if overrides_key not in overrides[m]:
                    overrides[m][overrides_key] = {}
                  if line_index not in overrides[m][overrides_key]:
                    overrides[m][overrides_key][line_index] = {}
                  overrides[m][overrides_key][line_index][edge] = assessment
                
                if advance(): return
            
            if advance(): return
        
        parse()
      
      if path.exists(manual_fes_paths[i]):
        for filename in listdir(manual_fes_paths[i]):
          mfes_file_path = path.join(manual_fes_paths[i], filename)
          mfes_file = open(mfes_file_path, 'r', encoding='utf-8')
          lines = mfes_file.read().splitlines()
          mfes_file.close()
          
          li = len(lines) - 1
          while li >= 0:
            line = lines[li].strip()
            
            if len(line) == 0:
              li -= 1
              continue
            
            line = line.split(':')[1].lstrip()
            
            if line != 'N/A':
              filename = filename.rsplit('.', 1)[0]
              filename, repeat = filename.split('_')
              mfes_key = (filename, repeat)
              
              false_edges = [tuple(int(vertex) for vertex in edge.split(','))
                             for edge in line.split('|')]
              
              manual_fes[m][mfes_key] = false_edges
            
            break
    
    for k in range(len(filenames)):
      filename = filenames[k]
      
      data_file_path = path.join(ps_data_dir, filename)
      data_file = open(data_file_path, 'r')
      lines = data_file.read().splitlines()
      data_file.close()
      
      edges = [tuple(int(vertex) for vertex in edge.split(','))
               for edge in lines[0].split('|')]
      problem_edges[k] = edges
      edges_set = set(edges)
      
      for m in range(len(mps_frame_indices)):
        i = mps_frame_indices[m]
        for j in range(len(repeat_dirs[m])):
          response_file_path = path.join(repeat_dirs[m][j], filename)
          ev = evals[m][j][k]
          
          if not path.exists(response_file_path) or ev is None:
            features[m][j].append(None)
            continue
          
          response_file = open(response_file_path, 'r', encoding='utf-8')
          lines = response_file.read().splitlines()
          response_file.close()
          coloring, evaluation = ev
          
          length = 0
          mentions_graph = False
          
          for line in lines:
            if len(line) == 0:
              continue
            
            length += len(get_clean_tokens(line))
            
            if not mentions_graph and 'graph' in line:
              mentions_graph = True
          
          repeat = path.basename(repeat_dirs[m][j])
          overrides_key = (filename, repeat)
          
          manual_fes_search = False
          es_to_count = None
          true_edges = None
          false_edges = None
          would_be_correct = None
          es_to_report = None
          
          if search_for_fes == 'all' or (search_for_fes == 'false_uncolorable'\
          and coloring == 'impossible' and evaluation == 'incorrect'):
            edge_statements = find_edge_statements(
              model, problem_set, frames[i], filename, lines)
            
            if edge_statements is None:
              manual_fes_search = do_manual_fes_search(
                model, problem_set, frames[i], filename, coloring, evaluation)
              if manual_fes_search and overrides_key in manual_fes[m]:
                es_to_count = set(manual_fes[m][overrides_key])
            else:
              es_to_count = set()
              es_to_report = {}
              
              for li in sorted(edge_statements.keys()):
                for edge in edge_statements[li]:
                  if edge not in es_to_count and edge not in edges_set:
                    if li not in es_to_report:
                      es_to_report[li] = (lines[li], set())
                    es_to_report[li][1].add(edge)
                  
                  es_to_count.add(edge)
              
              if overrides_key in overrides[m]:
                file_overrides = overrides[m][overrides_key]
                for li, line_overrides in file_overrides.items():
                  for edge, assessment in line_overrides.items():
                    if assessment == 'false positive' and edge in es_to_count:
                      es_to_count.remove(edge)
            
            if es_to_count is not None:
              true_edges = set()
              false_edges = set()
              num_invalid_edges = 0
              for statement in es_to_count:
                v1, v2 = statement
                if v1 >= 0 and v1 < num_vertices and v2 >= 0\
                and v2 < num_vertices and v1 != v2:
                  if statement in edges_set:
                    true_edges.add(statement)
                  else:
                    false_edges.add(statement)
                else:
                  false_edges.add(statement)
                  num_invalid_edges += 1
              
              if num_invalid_edges > 0 or coloring.startswith('not_found'):
                would_be_correct = False
              elif len(false_edges) == 0:
                would_be_correct = True
              else:
                alt_edges = edges_set.union(es_to_count)
                if coloring == 'impossible':
                  alt_vertex_conns = compute_vertex_conns(
                    num_vertices, alt_edges)
                  alt_coloring = color_greedy(
                    num_vertices, alt_vertex_conns, num_colors)
                  would_be_correct = (alt_coloring is None)
                else:
                  would_be_correct = coloring_is_valid(num_vertices,
                    alt_edges, string_to_coloring(coloring))
          
          features[m][j].append((length, mentions_graph, manual_fes_search,
            edges_to_string(true_edges), edges_to_string(false_edges),
            str(would_be_correct), es_to_report))
    
    for m in range(len(mps_frame_indices)):
      i = mps_frame_indices[m]
      features_file = open(features_file_paths[i], 'w')
      
      es_total = 0
      manual_fes_search_total = 0
      manual_fes_given = 0
      
      for k in range(len(filenames)):
        for j in range(len(repeat_dirs[m])):
          f = features[m][j][k]
          
          if f is None:
            continue
          
          length, mentions_graph, manual_fes_search, true_edges, false_edges,\
            would_be_correct, es_to_report = f
          
          if false_edges != 'None':
            es_total += 1
          
          if manual_fes_search:
            manual_fes_search_total += 1
            if false_edges != 'None':
              manual_fes_given += 1
          
          print('%s %s %d %s %s %s %s %s' % (filenames[k],
            path.basename(repeat_dirs[m][j]), length, mentions_graph,
            manual_fes_search, true_edges, false_edges, would_be_correct),
            file=features_file)
      
      features_file.close()
      
      if manual_fes_search_total > 0:
        makedirs(manual_fes_paths[i], exist_ok=True)
        
        for k in range(len(filenames)):
          filename = filenames[k]
          for j in range(len(repeat_dirs[m])):
            f = features[m][j][k]
            ev = evals[m][j][k]
            if f is None or ev is None:
              continue
            
            repeat = path.basename(repeat_dirs[m][j])
            mfes_file_path = path.join(manual_fes_paths[i],
                                       '%s_%s.txt' % (filename, repeat))
            manual_fes_search = f[2]
            if not manual_fes_search:
              if path.exists(mfes_file_path):
                remove(mfes_file_path)
              continue
            
            mfes_key = (filename, repeat)
            if mfes_key in manual_fes[m]:
              assessment = edges_to_string(manual_fes[m][mfes_key])
            else:
              assessment = 'N/A'
            
            mfes_file = open(mfes_file_path, 'w', encoding='utf-8')
            
            edges = problem_edges[k]
            edges_set = set(edges)
            edges_complement = [edge for edge in possible_edges\
                                if edge not in edges_set]
            
            print('Edges: %s' % edges, file=mfes_file)
            print('', file=mfes_file)
            print('Complement: %s' % edges_complement, file=mfes_file)
            print('', file=mfes_file)
            print('Evaluation: %s %s' % (ev[0], ev[1]), file=mfes_file)
            print('', file=mfes_file)
            print('---', file=mfes_file)
            print('', file=mfes_file)
            
            response_file_path = path.join(repeat_dirs[m][j], filename)
            response_file = open(response_file_path, 'r', encoding='utf-8')
            contents = response_file.read()
            response_file.close()
            
            print(contents, file=mfes_file)
            
            if frames[i] == 'friends':
              print('', file=mfes_file)
              print('---', file=mfes_file)
              print('Numericized:', file=mfes_file)
              print('---', file=mfes_file)
              print('', file=mfes_file)
              print(replace_each_whole_word(contents, friends_replace),
                    file=mfes_file)
            
            print('', file=mfes_file)
            print('---', file=mfes_file)
            print('', file=mfes_file)
            print('Manually assessed false edges: %s' % assessment,
                  file=mfes_file)
            
            mfes_file.close()
      
      if es_total - manual_fes_given > 0:
        makedirs(path.basename(false_es_file_paths[i]), exist_ok=True)
        false_es_file = open(false_es_file_paths[i], 'w', encoding='utf-8')
        
        for k in range(len(filenames)):
          for j in range(len(repeat_dirs[m])):
            f = features[m][j][k]
            if f is None:
              continue
            
            es_to_report = f[6]
            if es_to_report is None or len(es_to_report) == 0:
              continue
            
            repeat = path.basename(repeat_dirs[m][j])
            overrides_key = (filenames[k], repeat)
            if overrides_key in overrides[m]:
              file_overrides = overrides[m][overrides_key]
            else:
              file_overrides = None
            
            print('%s %s' % (filenames[k], path.basename(repeat_dirs[m][j])),
                  file=false_es_file)
            print('', file=false_es_file)
            
            for line_index in sorted(es_to_report.keys()):
              line, edges = es_to_report[line_index]
              print('Line %d' % (line_index + 1), file=false_es_file)
              print(line, file=false_es_file)
              print('', file=false_es_file)
              print('False edges:', file=false_es_file)
              
              for edge in sorted(edges):
                assessment = 'N/A'
                if file_overrides is not None and line_index in file_overrides:
                  line_overrides = file_overrides[line_index]
                  if edge in line_overrides:
                    assessment = line_overrides[edge]
                
                print('%s [Manual assessment: %s]' % (edge, assessment),
                      file=false_es_file)
              
              print('', file=false_es_file)
            
            print('---', file=false_es_file)
            print('', file=false_es_file)
        
        false_es_file.close()
